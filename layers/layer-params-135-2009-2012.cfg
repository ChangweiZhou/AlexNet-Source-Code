[conv1a]
epsW=0.0001
epsB=0.02
momW=0.9
momB=0.9
wc=0.0005
wball=0.00

[conv1b]
epsW=0.0001
epsB=0.02
momW=0.9
momB=0.9
wc=0.0005
wball=0.00

[conv2a]
epsW=0.0001,0.0001
epsB=0.02
momW=0.9,0.9
momB=0.9
wc=0.0005,0.0005
wball=0.00,0.00

[conv2b]
epsW=0.0001,0.0001
epsB=0.02
momW=0.9,0.9
momB=0.9
wc=0.0005,0.0005
wball=0.00,0.00

[conv3a]
epsW=0.0001,0.0001
epsB=0.02
momW=0.9,0.9
momB=0.9
wc=0.0005,0.0005
wball=0,0

[conv3b]
epsW=0.0001,0.0001
epsB=0.02
momW=0.9,0.9
momB=0.9
wc=0.0005,0.0005
wball=0,0

[conv4a]
epsW=0.0001
epsB=0.02
momW=0.9
momB=0.9
wc=0.0005
wball=0

[conv4b]
epsW=0.0001
epsB=0.02
momW=0.9
momB=0.9
wc=0.0005
wball=0

[conv5a]
epsW=0.0001
epsB=0.02
momW=0.9
momB=0.9
wc=0.0005
wball=0

[conv5b]
epsW=0.0001
epsB=0.02
momW=0.9
momB=0.9
wc=0.0005
wball=0

[fc2048a]
epsW=0.0001,0.0001
epsB=0.02
momW=0.9,0.9
momB=0.9
wc=0.0005,0.0005
wball=0,0

[fc2048b]
epsW=0.0001,0.0001
epsB=0.02
momW=0.9,0.9
momB=0.9
wc=0.0005,0.0005
wball=0,0

[fc2048ba]
epsW=0.0001,0.0001
epsB=0.02
momW=0.9,0.9
momB=0.9
wc=0.0005,0.0005
wball=0,0

[fc2048bb]
epsW=0.0001,0.0001
epsB=0.02
momW=0.9,0.9
momB=0.9
wc=0.0005,0.0005
wball=0,0

[fc1000]
epsW=0.0001,0.0001
epsB=0.02
momW=0.9,0.9
momB=0.9
wc=0.0005,0.0005
wball=0,0

[logprob]
coeff=1
topk=5

[hs1a]
enable=true

[hs2a]
enable=true

[hs1b]
enable=true

[hs2b]
enable=true

[rnorm1a]
scale=0.0001
pow=0.75
minDiv=2

[rnorm1b]
scale=0.0001
pow=0.75
minDiv=2

[rnorm2a]
scale=0.0001
pow=0.75
minDiv=2

[rnorm2b]
scale=0.0001
pow=0.75
minDiv=2

[cnorm2a]
scale=0.001
pow=0.75

[cnorm2b]
scale=0.001
pow=0.75

# this trains 135 on 2012, initialized from 2009 1-8800
# on guppy9
# init epsw 0.001
# logs/layers-135-2012-pretrain-2009.log
# /nobackup/kriz/tmp/ConvNet__2012-09-09_15.20.47
# epoch 22: set epsw to 0.0001 from 0.001
# epoch 23: putting on hold to train softmax tree
#           this is doing worse than 141-2009 anyway, which has an extra 6th conv layer (1.97 vs 2.00)

# 135 notes:
# this is like #131, but with minDiv of 2 on rnorms
# on guppy8
# /nobackup/kriz/tmp/ConvNet__2012-08-21_01.49.23
# logs/layers-135.log
# epoch 20: set epsw to 0.001 from 0.01
# epoch 47: set epsw to 0.0001 from 0.001
# epoch 66: set epsw to 0.00001 from 0.0001 on conv1,conv2
#           set color noise to 0 from 0.1
# epoch 75: set epsw to 0 from 0.00001 on conv1,conv2
# epoch 81: set epsw to 0.00001 from 0.0001
# epoch 96: killed
# validation multiview: 
# logprob:  1.757653, 0.410700, 0.184160 

# now let's train on 2009 1-8800
# logs/layers-135-2009-bigtrain.log
# on guppy9
# /nobackup/kriz/tmp/ConvNet__2012-08-26_22.39.45
# epoch 4.7822: set epsw to 0.001 from 0.01
# epoch 8.1299: set epsw to 0.0001 from 0.001
# epoch 10.3697: set epsw to 0.00001 from 0.0001 on conv1,conv2
#           set color noise to 0 from 0.1
# epoch 11.4731: set epsw to 0 from 0.00001 on conv1,conv2
# epoch 14.3906: set epsw to 0.00001 from 0.0001
# epoch 17: killed
